{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import success!\n",
      "Starting data processing...\n",
      "Processed data for 1996\n",
      "Processed data for 1997\n",
      "Processed data for 1998\n",
      "Processed data for 1999\n",
      "Processed data for 2000\n",
      "Processed data for 2001\n",
      "Processed data for 2002\n",
      "Processed data for 2003\n",
      "Processed data for 2004\n",
      "Processed data for 2005\n",
      "Processed data for 2006\n",
      "Processed data for 2007\n",
      "Processed data for 2008\n",
      "Processed data for 2009\n",
      "Processed data for 2010\n",
      "Processed data for 2011\n",
      "Processed data for 2012\n",
      "Processed data for 2013\n",
      "Processed data for 2014\n",
      "Processed data for 2015\n",
      "Processed data for 2016\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Main execution\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting data processing...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m final_df \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_all_years\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(final_df\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m, in \u001b[0;36mprocess_all_years\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Combine all intermediate files\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([pd\u001b[38;5;241m.\u001b[39mread_csv(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcookie_tracking_data_up_to_\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m     53\u001b[0m final_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcookie_tracking_data_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal data saved to cookie_tracking_data_final.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m     gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Combine all intermediate files\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcookie_tracking_data_up_to_\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m     53\u001b[0m final_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcookie_tracking_data_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal data saved to cookie_tracking_data_final.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/site-packages/pandas/_libs/parsers.pyx:554\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import functools\n",
    "import gc\n",
    "\n",
    "print(\"Import success!\")\n",
    "\n",
    "@functools.lru_cache(maxsize=1)\n",
    "def reviveEngine(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def process_year(year):\n",
    "    engine = reviveEngine(f'/app/Data/waybackCollectedData/usenix{year}.pickle')\n",
    "    cookie_data = []\n",
    "    for site in engine.getAllSitesWithTrackers():\n",
    "        for tracker, types in engine.sitesToTrackersToTypes[site].items():\n",
    "            if 'C' in types:\n",
    "                cookie_data.append({\n",
    "                    'year': year,\n",
    "                    'domain': site,\n",
    "                    'tracker': tracker,\n",
    "                    'types': ','.join(types)\n",
    "                })\n",
    "    del engine\n",
    "    gc.collect()\n",
    "    return cookie_data\n",
    "\n",
    "def process_all_years():\n",
    "    all_data = []\n",
    "    for year in range(1996, 2017):\n",
    "        year = str(year)\n",
    "        year_data = process_year(year)\n",
    "        all_data.extend(year_data)\n",
    "        print(f\"Processed data for {year}\")\n",
    "        \n",
    "        # Save intermediate results to prevent data loss\n",
    "        temp_df = pd.DataFrame(all_data)\n",
    "        temp_df.to_csv(f'cookie_tracking_data_up_to_{year}.csv', index=False)\n",
    "        \n",
    "        # Clear memory\n",
    "        del year_data\n",
    "        del temp_df\n",
    "        all_data = []\n",
    "        gc.collect()\n",
    "    \n",
    "    # Combine all intermediate files\n",
    "    final_df = pd.concat([pd.read_csv(f) for f in os.listdir('.') if f.startswith('cookie_tracking_data_up_to_')])\n",
    "    final_df.to_csv('cookie_tracking_data_final.csv', index=False)\n",
    "    print(\"Final data saved to cookie_tracking_data_final.csv\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Main execution\n",
    "print(\"Starting data processing...\")\n",
    "final_df = process_all_years()\n",
    "print(final_df.head())\n",
    "print(final_df.shape)\n",
    "\n",
    "# Optional: Remove intermediate files\n",
    "for f in os.listdir('.'):\n",
    "    if f.startswith('cookie_tracking_data_up_to_'):\n",
    "        os.remove(f)\n",
    "print(\"Intermediate files removed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'engines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     final_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcookie_tracking_data_final.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal data saved to cookie_tracking_data_final.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m process_all_years(\u001b[43mengines\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'engines' is not defined"
     ]
    }
   ],
   "source": [
    "def process_year(year, engine):\n",
    "    cookie_data = []\n",
    "    for site in engine.getAllSitesWithTrackers():\n",
    "        for tracker, types in engine.sitesToTrackersToTypes[site].items():\n",
    "            if 'C' in types:\n",
    "                cookie_data.append({\n",
    "                    'year': year,\n",
    "                    'domain': site,\n",
    "                    'tracker': tracker,\n",
    "                    'types': ','.join(types)\n",
    "                })\n",
    "    return cookie_data\n",
    "\n",
    "def process_all_years(engines):\n",
    "    all_data = []\n",
    "    for year, engine in engines.items():\n",
    "        year_data = process_year(year, engine)\n",
    "        all_data.extend(year_data)\n",
    "        print(f\"Processed data for {year}\")\n",
    "        \n",
    "        # Save intermediate results to prevent data loss\n",
    "        temp_df = pd.DataFrame(all_data)\n",
    "        temp_df.to_csv(f'cookie_tracking_data_up_to_{year}.csv', index=False)\n",
    "        \n",
    "        # Clear memory\n",
    "        del year_data\n",
    "        all_data = []\n",
    "    \n",
    "    # Combine all intermediate files\n",
    "    final_df = pd.concat([pd.read_csv(f) for f in os.listdir('.') if f.startswith('cookie_tracking_data_up_to_')])\n",
    "    final_df.to_csv('cookie_tracking_data_final.csv', index=False)\n",
    "    print(\"Final data saved to cookie_tracking_data_final.csv\")\n",
    "\n",
    "process_all_years(engines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cookie_data(engines):\n",
    "    all_cookie_data = []\n",
    "    for year, engine in engines.items():\n",
    "        for site in engine.getAllSitesWithTrackers():\n",
    "            for tracker, types in engine.sitesToTrackersToTypes[site].items():\n",
    "                if 'C' in types:  # 'C' represents cookie-based tracking\n",
    "                    all_cookie_data.append({\n",
    "                        'year': year,\n",
    "                        'domain': site,\n",
    "                        'tracker': tracker,\n",
    "                        'types': ','.join(types)\n",
    "                    })\n",
    "        print(f\"Processed data for {year}\")\n",
    "    return all_cookie_data\n",
    "\n",
    "cookie_data = extract_cookie_data(engines)\n",
    "df = pd.DataFrame(cookie_data)\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cookie_data(engine, year):\n",
    "    cookie_data = []\n",
    "    for site in engine.getAllSitesWithTrackers():\n",
    "        for tracker, types in engine.sitesToTrackersToTypes[site].items():\n",
    "            if 'C' in types:  # 'C' represents cookie-based tracking\n",
    "                cookie_data.append({\n",
    "                    'year': year,\n",
    "                    'domain': site,\n",
    "                    'tracker': tracker\n",
    "                })\n",
    "    return cookie_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dir = '/app/Data/waybackCollectedData/'  # Replace with your actual path\n",
    "years = range(1996, 2017)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_years(pickle_dir, years):\n",
    "    all_cookie_data = []\n",
    "    for year in years:\n",
    "        file_path = os.path.join(pickle_dir, f'usenix{year}.pickle')\n",
    "        try:\n",
    "            engine = load_pickle(file_path)\n",
    "            year_data = extract_cookie_data(engine, year)\n",
    "            all_cookie_data.extend(year_data)\n",
    "            print(f\"Processed data for {year}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {year}: {e}\")\n",
    "    return all_cookie_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for 1996\n",
      "Processed data for 1997\n",
      "Processed data for 1998\n",
      "Processed data for 1999\n",
      "Processed data for 2000\n",
      "Processed data for 2001\n",
      "Processed data for 2002\n",
      "Processed data for 2003\n",
      "Processed data for 2004\n",
      "Processed data for 2005\n",
      "Processed data for 2006\n",
      "Processed data for 2007\n",
      "Processed data for 2008\n",
      "Processed data for 2009\n",
      "Processed data for 2010\n",
      "Processed data for 2011\n",
      "Processed data for 2012\n",
      "Processed data for 2013\n",
      "Processed data for 2014\n",
      "Processed data for 2015\n",
      "Processed data for 2016\n",
      "   year         domain                tracker\n",
      "0  2004    gaoshou.net              baidu.com\n",
      "1  2004    99lover.com              17777.com\n",
      "2  2004  61.152.97.111          61.152.97.111\n",
      "3  2004       3tom.com              baidu.com\n",
      "4  2006        alt.com  adultfriendfinder.com\n",
      "(8, 3)\n"
     ]
    }
   ],
   "source": [
    "all_cookie_data = process_all_years(pickle_dir, years)\n",
    "df = pd.DataFrame(all_cookie_data)\n",
    "print(df.head())\n",
    "print(df.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
